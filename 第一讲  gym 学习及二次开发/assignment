import numpy as np
from functools import reduce
import matplotlib.pyplot as plt

# np.random.seed(3)
mu = np.array([0,1,2,4,8,10,20,50,80,100])
Sigma = np.array([[10, 4, 8, 4, 10, 4, 4, 0, 6, 8],[4, 6, 2, 4, 6, 4, 4, 2, 2, 4],\
                  [8, 2, 10, 4, 10, 6, 2, 0, 4, 8],[4, 4, 4, 8, 6, 8, 4, 4, 2, 6],\
                  [10, 6, 10, 6, 18, 10, 8, 4, 8, 12],[4, 4, 6, 8, 10, 12, 6, 6, 4, 8], \
                  [4, 4, 2, 4, 8, 6, 8, 4, 6, 4],[0, 2, 0, 4, 4, 6, 4, 6, 2, 2],\
                  [6, 2, 4, 2, 8, 4, 6, 2, 8, 4],[8, 4, 8, 6, 12, 8, 4, 2, 4, 14]])
n = 3000

def simulate_nan(X, nan_rate):
    '''(np.array, number) -> {str: np.array or number}
    Preconditions:
    1. np.isnan(X_complete).any() == False
    2. 0 <= nan_rate <= 1
    Return the dictionary with four keys where:
    - Key 'X' stores a np.array where some of the entries in X
    are replaced with np.nan based on nan_rate specified.
    - Key 'C' stores a np.array where each entry is False if the
    corresponding entry in the key 'X''s np.array is np.nan, and True
    otherwise.
    - Key 'nan_rate' stores nan_rate specified.
    - Key 'nan_rate_actual' stores the actual proportion of np.nan
    in the key 'X''s np.array.
    '''
    # Create C matrix; entry is False if missing, and True if observed
    X_complete = X.copy()
    nr, nc = X_complete.shape
    C = np.random.random(nr * nc).reshape(nr, nc) > nan_rate
    # Check for which i's we have all components become missing
    checker = np.where(sum(C.T) == 0)[0] 
    if len(checker) == 0:
        # Every X_i has at least one component that is observed, 
        # which is what we want
        X_complete[C == False] = np.nan
    else:
        # Otherwise, randomly "revive" some components in such X_i's 
        for index in checker:
            reviving_components = np.random.choice(
                 nc,
                 int(np.ceil(nc * np.random.random())),
                 replace = False
            )
            C[index, np.ix_(reviving_components)] = True
        X_complete[C == False] = np.nan
    result = {
        'X': X_complete,
        'C': C,
        'nan_rate': nan_rate,
        'nan_rate_actual': np.sum(C == False) / (nr * nc)
    }
    return result
        
def impute_em(X, max_iter = 3000, eps = 1e-05): 
    '''(np.array, int, number) -> {str: np.array or int}
    Precondition: max_iter >= 1 and eps > 0
    Return the dictionary with five keys where:
    - Key 'mu' stores the mean estimate of the imputed data.
    - Key 'Sigma' stores the variance estimate of the imputed data.
    - Key 'X_imputed' stores the imputed data that is mutated from X using
    the EM algorithm.
    - Key 'C' stores the np.array that specifies the original missing entries
    of X.
    - Key 'iteration' stores the number of iteration used to compute
    'X_imputed' based on max_iter and eps specified.
    '''
    nr, nc = X.shape
    C = np.isnan(X) == False
    # Collect M_i and O_i's
    one_to_nc = np.arange(1, nc + 1, step = 1)
    M = one_to_nc * (C == False) - 1
    O = one_to_nc * C - 1
    # Generate Mu_0 and Sigma_0
    Mu = np.nanmean(X, axis = 0)
    observed_rows = np.where(np.isnan(sum(X.T)) == False)[0] 
    S = np.cov(X[observed_rows, ].T)
    if np.isnan(S).any():
        S = np.diag(np.nanvar(X, axis = 0))
    # Start updating
    Mu_tilde, S_tilde = {}, {}
    X_tilde = X.copy()
    no_conv = True
    iteration = 0
    while no_conv and iteration < max_iter: 
        for i in range(nr):
            S_tilde[i] = np.zeros(nc ** 2).reshape(nc, nc)
            if set(O[i, ]) != set(one_to_nc - 1): # missing component exists
                M_i, O_i = M[i, ][M[i, ] != -1], O[i, ][O[i, ] != -1]
                S_MM = S[np.ix_(M_i, M_i)]
                S_MO = S[np.ix_(M_i, O_i)]
                S_OM = S_MO.T
                S_OO = S[np.ix_(O_i, O_i)]
                Mu_tilde[i] = Mu[np.ix_(M_i)] +\
                 S_MO @ np.linalg.inv(S_OO) @\
                 (X_tilde[i, O_i] - Mu[np.ix_(O_i)])
                X_tilde[i, M_i] = Mu_tilde[i]
                S_MM_O = S_MM - S_MO @ np.linalg.inv(S_OO) @ S_OM
                S_tilde[i][np.ix_(M_i, M_i)] = S_MM_O
        Mu_new = np.mean(X_tilde, axis = 0)
        S_new = np.cov(X_tilde.T, bias = 1) +\
        reduce(np.add, S_tilde.values()) / nr
        no_conv =\
        np.linalg.norm(Mu - Mu_new) >= eps or\
        np.linalg.norm(S - S_new, ord = 2) >= eps
        Mu = Mu_new
        S = S_new
        iteration += 1
    result = {
         'mu': Mu,
         'Sigma': S,
         'X_imputed': X_tilde,
         'C': C,
         'iteration': iteration
    }
    return result

def estimate(nan_rate):
    X_truth = np.random.multivariate_normal(mu, Sigma, n)
    ested_mu = np.zeros((1,10))
    ested_Sigma = np.zeros((10,10))
    for i in range(10):
        result = simulate_nan(X_truth, nan_rate)
        X = result['X'].copy()
        result_imputed = impute_em(X)
        ested_mu += result_imputed['mu']
        ested_Sigma += result_imputed['Sigma']
    print('True mean vector:', end = ' ')
    print([round(a,2) for a in mu])
    print('Mean of the estimated mean vector:', end = ' ')
    print([round(a,2) for a in ested_mu/10])
    
    
    # print(np.matrix.round(ested_mu/10,2))
    
    print('std of the estimated mean vector:', end = ' ')
    print(round(np.linalg.norm(mu - ested_mu/10), 4))
    print()
    print('True sigma:', end = ' ')
    print(Sigma)
    print('Mean of the estimated sigma:', end = ' ')
    print(np.matrix.round(ested_Sigma/10,2))
    print('std of the eean of the estimated sigma:', end = ' ')
    print(round(np.linalg.norm(Sigma - ested_Sigma/10),4))
    return ested_mu/10, ested_Sigma/10

    

ested_mu_05, ested_Sigma_05 = estimate(0.05)


ested_mu_1, ested_Sigma_1 = estimate(0.1)


ested_mu_2, ested_Sigma_2 = estimate(0.2)


ested_mu_3, ested_Sigma_3 = estimate(0.3)


ested_mu_4, ested_Sigma_4 = estimate(0.4)


plt.plot([ested_mu_05, ested_mu_1, ested_mu_2, ested_mu_3, ested_mu_4], [ested_Sigma_05, ested_Sigma_1, \
                     ested_Sigma_2, ested_Sigma_3, ested_Sigma_4])
